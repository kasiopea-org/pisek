[task]
version=
use=
task_type=
score_precision=

[tests]
in_gen=
gen_type=
in_format=
out_format=
validator=

out_check=
out_judge=
#!if tests out_check=judge
judge_type=
#!if tests out_check=judge
judge_needs_in=
#!if task task_type=batch
#!if tests out_check=judge
judge_needs_out=
#!if task task_type=batch
#!if tests out_check=judge

tokens_ignore_newlines=
#!if tests out_check=tokens
tokens_ignore_case=
#!if tests out_check=tokens
tokens_float_rel_error=
#!if tests out_check=tokens
tokens_float_abs_error=
#!if tests out_check=tokens

shuffle_mode=
#!if tests out_check=shuffle
shuffle_ignore_case=
#!if tests out_check=shuffle

static_subdir=

name=
in_globs=
predecessors=

[test\d{2}]
#!regex
#!default tests
name=
points=
in_globs=
predecessors=

[solution_(.*)]
#!regex
#!default solutions

run=
primary=

points=
#!if solution_(.*) points_min=X
#!if solution_(.*) points_max=X
points_min=
#!if solution_(.*) points=X
points_max=
#!if solution_(.*) points=X

tests=
subtasks=

[solutions]
run=
primary=
points=
points_min=
points_max=
tests=
subtasks=
stub=
headers=

[run]
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_gen]
#!default run
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_gen_(.*)]
#!regex
#!default run_gen
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_validator]
#!default run
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_validator_(.*)]
#!regex
#!default run_validator
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_solution]
#!default run
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_primary_solution]
#!default run_solution
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_secondary_solution]
#!default run_solution
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_solution_(.*)]
#!regex
#!dynamic_default
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_judge]
#!default run
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

[run_judge_(.*)]
#!regex
#!default run_judge
exec=
time_limit=
clock_mul=
clock_min=
mem_limit=
process_limit=
args=
subdir=

# TODO: Add in other defaults & description
[build]
sources=
comp_args=
extras=
strategy=
entrypoint=

[build_solution]
cms_stub=
cms_headers=

[limits]
input_max_size=
output_max_size=

[checks]
solution_for_each_test=
no_unused_inputs=
all_inputs_in_last_test=
generator_respects_seed=
one_input_in_each_nonsample_test=
judge_handles_fuzzed_outputs=

[cms]
name=
title=
submission_format=
time_limit=
mem_limit=
max_submissions=
min_submission_interval=
score_mode=
feedback_level=
