# Example and explanation of a config file for task made in pisek

# !!! Config version 3 is experimental and can be changed !!!
# TODO comments indicate future changes

# Move 'config' into a task folder

# Values beginning with ! or @ are reserved and have special meaning:
# - Only ! value is !unset, which is always invalid
# - @ values autoexpand depending on context

# Bool type switches can have the following values:
# True values:
#   - 1, True, true, t, yes, y, on
# False values:
#   - 0, False, false, f, no, n, off


[task]

version=v3
# Task version
# - v1 - Old version with a basic set of options. (default)
# - v2 - Current stable version, Added solution sections and redone test sections.
# - v3 - Current experimental version, generalized contest_type to use. More changes incoming.
# The version applies to this config file only and cannot be inherited with the use key.

# You can use 'pisek update' to update the config to the highest version.

use=organization-config
# Config to use defaults from (defaults to none)

# Values of keys are loaded in the following way:
# 1. We try to find a given (section,key) in the task config
# 2. If not found, we go to the config specified by the use key.
# 3. If we are in the topmost config, we reset to the task config and
#    try searching for the defaulting section and key of this key.
# 4. If there is no defaulting key, we either return the default value, or fail if there is none.
#
# For example, consider:
#   use=organization-config
#   ([section],key) defaults to ([default_section],key)
#   ([default_section],key) defaults to 42 if not present
# Then we search in this order:
# 1. this config,         [section], key
# 2. organization-config, [section], key
# 3. this config,         [default_section], key
# 4. organization-config, [default_section], key
# 5. If still not found, return 42

task_type=interactive
# Task type:
# - batch (default)
# - interactive

score_precision=0
# How many decimal digits scores are rounded to (defaults to 0)

[tests]

in_gen=gen
# Reference to the run section specifying how to run the generator (if empty, only static inputs are used)
# See [run] for more

gen_type=opendata-v1
# Specifies the generator type. (required)
# - pisek-v1 (recommended)
# - cms-old
# - opendata-v1
# For more see docs/generator.md

in_format=strict-text
out_format=text
# Format of input/output:
#   text        UTF-8 or UTF-16 encoded ASCII printable characters, with an optional BOM. (default for out_format)
#               All lines (including the last one) are automatically converted to be terminated with a LF character.
#   strict-text ASCII printable characters. (default for in_format)
#               All lines (including the last one) must already be terminated with a LF character.
#   binary      Can be anything.

validator=validate
# Reference to the run section specifying how to run the validator
# See [run] for more
#
# No value means no checking (default)

out_check=judge
# Describes how to check outputs (required)
#   - diff: compare with correct output (discouraged, can be slow in some cases)
#   - tokens: compare token-by-token with correct output (tokens are separated by whitespace)
#   - shuffle: like tokens, but allow permutation of tokens
#   - judge: check with a custom program (called a 'judge')
# In interactive, only judge is allowed
# For more see docs/batch_judge.md or docs/interactive_judge.md

out_judge=judge
# Only for out_check=judge (required in that case)
# Reference to the run section specifying how to run the judge
# See [run] for more

judge_type=cms-batch
# Only for out_check=judge (required in that case)
# Specifies how to call judge and how judge reports result
#
# For task_type=batch:
# - cms-batch
#       https://cms.readthedocs.io/en/v1.4/Task%20types.html?highlight=manager#checker
# - opendata-v1
#       ./judge <test> <seed> < output
#       $TEST_INPUT=[input] $TEST_OUTPUT=[correct_output]
#       return code 0 means correct, 1 wrong
#
# For task_type=interactive:
# - cms-communication
#       https://cms.readthedocs.io/en/v1.4/Task%20types.html?highlight=manager#communication
#
# See docs/batch_judge.md or docs/interactive_judge.md for details

judge_needs_in=0
judge_needs_out=0
# Only for task_type=batch and out_check=judge
# Whether the judge needs the input/correct output (bool)
# Both default to true

tokens_ignore_newlines=0
# Only for out_check=tokens
# If set to true, newline characters will be ignored when checking the output,
# as if they were any other whitespace characters
# If set to false, newline characters are only ignored at the end of the file (default)

tokens_ignore_case=0
# Only for out_check=tokens
# If set to true, ASCII characters will be compared in a case-insensitive manner (defaults to false)

tokens_float_rel_error=0.00001
tokens_float_abs_error=1e-30
# Only for out_check=tokens
# When these options are specified, floating-point numbers
# will be parsed and compared with a given error margin
# Any tokens that can't be parsed as a float will be compared character-by-character
# If used, both of these options must be specified
# To explicitly disable float checking, set both options to the empty string (default)

shuffle_mode=lines
# Only for out_check=shuffle (required in that case)
# Which permutations are allowed:
#   lines       Permutation of lines
#   words       Permutation of words within each line
#   lines_words Both lines and words
#   tokens      Permutation of all tokens, ignoring line boundaries

shuffle_ignore_case=0
# Only for out_check=shuffle
# If set to true, ASCII characters will be compared in a case-insensitive manner (defaults to false)

static_subdir=static_tests/
# Try to find static inputs and outputs in this folder relative to config (defaults to .)

# Defaults for [testXX] keys:

name=@auto
# Name of the test
# @auto expands to "Test [test number]" (default)

points=2
# Number of points for this test (<int>)
# (required in [tests] or each [testXX])

in_globs=@ith
# Which new inputs are introduced in this test.
# Supports expansion of * and ? as in shell
# @ith expands to {test_number:02}*.in (default)

predecessors=
# Space separated list of test easier than this test
# Inputs from these test are included into this test as well
# @previous expands to previous test (or nothing if test has number <= 1)

[test01]
# Section for each test (indexed from one)
# Keys default to [tests] keys if not set
name=Test 1
points=3
in_globs=01*.in
predecessors=

[test00]
# Section for samples test
# Can be omitted and has the following defaults: (doesn't use [tests] defaults)
name=Samples
points=0
in_globs=sample*.in
predecessors=

[solution_correct]
# Section for each solution
# This solution is named "correct"
# Keys default to [solution] keys

run=solve
# Reference to the run section specifying how to run this solution
# See [run] for more
#
# @auto expands to name of the section without "solution_" (in this case to "correct") (default)

primary=yes
# Use this solution to generate correct outputs? (bool, defaults to false)
# Exactly one solution has to be set to primary
# (or zero if there are no solutions in config)

points=10
# Points that program should get or X for any number of points (defaults to X)

points_min=5
points_max=7
# Upper and lower bounds on points (defaults to X)
# Cannot be set simultaneously with points

tests=X10
# String describing result on each test:
# 1 - success
# 0 - fail
# P - partial success
# W - wrong answer
# ! - runtime error
# T - timeout
# X - any result
#
# The result of a test is the result of the worst testcase.
# W!T require at least one testcase with the corresponding verdict.
#
# @all - string of 11...
# @any - string of XX...
# @auto - @all if this is primary solution, @any otherwise (default)

[solutions]
# Defaults for all solutions
# If not specified the defaults are:
run=@auto
primary=no
points=X
points_min=X
points_max=X
tests=@auto

# There are also keys that are specific to [solutions]
# and cannot be configured on a per solution basis:

[run]
# Sections describing running a program.
#
# The run section for each program is optional. If it is missing, its contents are autogenerated,
# by looking for most specific section with the given key set, according to this hierarchy:
#                                          [run]
#       [run_gen]          [run_validator]          [run_judge]                         [run_solution]
#                                                                    [run_primary_solution] [run_secondary_solution]
# [run_gen:{program}] [run_validator:{program}] [run_judge:{program}]              [run_solution:{program}]

build=@auto
# Reference to the build section specifying how to build this program
# @auto expands to '{program_type}:{subdir}/{program}', e.g. 'solution:solutions/solve' (default)
# See [build] for more 

exec=@auto
# Filename of the program to execute (without suffix)
# @auto expands to {program} (default)
args=--slow
# Additional arguments for the program. (Given before any other arguments.)
# (defaults to empty)
subdir=
# Subdirectory from where to look for the program (relative to the task directory)
# (defaults to empty)

# Execution limits, setting limit to 0 means unlimited. Defaults are the following:
time_limit=360
# Execution time limit [seconds] (defaults to 360 s)
clock_mul=
# Wall clock multiplier [1] (defaults to 2x)
clock_min=
# Wall clock minimum [second] (defaults to 1 s)
mem_limit=
# Memory limit [MB] (defaults to unlimited)
process_limit=
# Maximum number of processes -- at the moment,
# limits greater than 1 are interpreted as "unlimited". (defaults to 1)
# Please keep in mind that killing multiple processes
# upon errors is inherently unreliable.

[run_gen]
# Overriding process_limit for generator
process_limit=0

[run_solution]
# Overriding time_limit for solutions
time_limit=3

[run_solution:slow]
# Overriding time_limit for specific solution
time_limit=10

[build]
# Sections describing building a program.
#
# The build section for each program is optional. If it is missing, its contents are autogenerated,
# by looking for most specific section with the given key set, according to this hierarchy:
#                                                    [build]
#  [build:{program}]       [build_gen]          [build_validator]          [build_judge]            [build_solution]
#                    [build_gen:{program}] [build_validator:{program}] [build_judge:{program}] [build_solution:{program}]

sources=@auto
# List of sources needed for building the executable
# @auto expands to {program} (default)
comp_args=
# Additional compiler arguments, appended to the end
# Defaults to empty
extras=
# Additional files to be copied to the build directory
entrypoint=
# For building some executables (e.g. python), entrypoint is needed.
# Defaults to empty
strategy=auto
# Build strategy for building this program
# 'auto' detects automatically which strategy to use (defaults)
# Other strategies are:
# - python
# - shell
# - c
# - cpp
# - pascal

headers_c=
# Headers to include in the c strategy (defaults to empty)
extra_sources_c=
# Extra source files for the c strategy (defaults to empty)
headers_cpp=
# Headers to include in the cpp strategy (defaults to empty)
extra_sources_cpp=
# Extra source files for the cpp strategy (defaults to empty)

[limits]
# Section with input/output size limits.

input_max_size=20
# Maximal input size [MB]
# (0 for unlimited) (defaults to 50)

output_max_size=5
# Maximal input size [MB]
# (0 for unlimited) (defaults to 10)

[checks]
# Sections for enabling/disabling checks that task must satisfy

# Please be careful with this section as disabling checks can make
# task making into a minefield

# Each value is a bool:

solution_for_each_test=off
# checks that a dedicated solution exists for each test (aside from samples) (defaults to off)
# A dedicated solution for a test is one that:
# - Gets full points on this test and its predecessors.
# - Doesn't get full points on other test.

no_unused_inputs=on
# checks that there are no unused inputs in the entire task: (defaults to on)
# - In static_subdir
# - Generated by generator

all_inputs_in_last_test=off
# checks that all inputs are included in the last test (defaults to off)

generator_respects_seed=on
# Checks that the generator generates two different inputs for two different seeds (defaults to on)

one_input_in_each_nonsample_test=off
# Checks that each test (excluding samples) contains exactly one input (defaults to off)
# Useful for opendata tasks

judge_handles_fuzzed_outputs=on
# Checks that the judge doesn't crash on random outputs. (defaults to on)
# The tested outputs are generated by modifying sample outputs.

[cms]
# Settings related to the CMS importer
# See CMS docs (https://cms.readthedocs.io/en/latest/) for details

name=a-plus-b
# Name of task, which will appear in the task URL (required for CMS commands)
title=A plus B
# The name of the task shown on the task description page 
# @name expands to the task name (default)
submission_format=adder.%l
# The name of the submitted file
# .%l will be replaced with the language's file extension
# @name expands to to the task name with non-alphanumeric characters replaced with _ and .%l appended (default)

time_limit=1
# Execution time limit [seconds] (defaults to 1)
mem_limit=1024
# Memory limit [MB] (defaults to 1024)

max_submissions=50
# The number of submissions one contestant allowed to make, or X for unlimited (defaults to 50)
min_submission_interval=60
# The number of seconds a contestant has to wait between consecutive submissions (defaults to 0)

score_mode=max_subtask
# Describes how the final score is computed from the scores of individual submissions
# May be 'max', 'max_subtask' (default) or 'max_tokened_last'
feedback_level=restricted
# Specifies how much information is given to the contestants about their submission
# May be 'full' or 'restricted' (default)

stub=src/stub
# Only for C/C++
# Link each solution with given program (without suffix) (defaults to none)
# Used commonly for interactive tasks

headers=src/a-plus-b.h
# Only for C/C++
# Allow each solution to include the given headers (defaults to none)
# Used commonly for interactive tasks
